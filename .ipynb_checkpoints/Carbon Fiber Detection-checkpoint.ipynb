{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f5fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0834fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best fiber extraction: Threshold Binary70 + Guassian Otsu's Thresholding\n",
    "# best centre line: Threshold Binary70inv + closing + skel + remove small 1 contours\n",
    "# 先threshould 根据边界框框crop crop完了直接用binary的图片提取12个trajectory 然后每个trajetory和GT的进行\n",
    "# overlay 计算不同粗细的precision\n",
    "# 还有一个metric就是RMSE计算pred每个pixel的位置和最近的GT的pixel的欧拉距离 但是不是很好算 要么就算了。\n",
    "# 应该先提取fiber 然后croped了再分别不同trajectory再识别中心线 没有合适的metric就是说。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b4de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取fiber部分\n",
    "def extract_cline_fiber(pic):\n",
    "    ret,thresh1 = cv2.threshold(pic, 210, 255, cv2.THRESH_BINARY_INV)\n",
    "    blur = cv2.GaussianBlur(thresh1, (5,5), 0)#blur的size可以修改\n",
    "    _, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return th3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0328ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取12个图片的黑白版本\n",
    "files = glob('12 fiber pics\\\\*.*')\n",
    "for file in files:\n",
    "    name = list(file.split('\\\\'))[-1]\n",
    "    pic = cv2.imread(file, 0)\n",
    "    new_pic = extract_cline_fiber(pic)\n",
    "    cv2.imwrite('12 fiber pics\\\\extracted_' + name, new_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c700d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里要搞一个根据框截图图片的function 从image变成croped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1fc9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入crop的binary图片，输出12个trajectory叠在一起的图和对应的\n",
    "def get_traj(pic):\n",
    "    contours, hierarchy = cv2.findContours(pic, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    lefts = []\n",
    "    trajs = np.zeros([pic.shape[0],pic.shape[1],12])\n",
    "    \n",
    "    for i in range(len(sorted_contours)):\n",
    "        c = sorted_contours[i]\n",
    "        area = cv2.contourArea(c)\n",
    "        if (area < 100 and i < 12) or (area >= 100 and i >= 12):\n",
    "            print('Disconnection may exist! Please check!')\n",
    "        elif area >= 100 and i < 12:\n",
    "            traj = cv2.drawContours(np.zeros(pic.shape),[c],0,255,-1)\n",
    "            trajs[:,:,i] = traj\n",
    "            l = np.where(traj!=0)[1].min()\n",
    "            lefts.append(l)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ordered = np.zeros(trajs.shape)\n",
    "    n = 0\n",
    "    for i in np.argsort(np.array(lefts)):\n",
    "        ordered[:,:,n] = trajs[:,:,i]\n",
    "        n+=1\n",
    "        \n",
    "    return ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe8f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据evaluate的曲线位置（0-11）和evaluate的range（1,2,3意味着几倍）生成取样区域\n",
    "def eva_area(img, pos=1, rang=1):\n",
    "    \n",
    "    num = pos//3\n",
    "    loc = pos%3\n",
    "    center = 130+300*num\n",
    "    pic = np.zeros([630, 1160])\n",
    "    if loc == 2:\n",
    "        R = 25\n",
    "    elif loc == 1:\n",
    "        R = 50\n",
    "    elif loc == 0:\n",
    "        R = 100\n",
    "    \n",
    "    thick = np.round(rang*6.5).astype(int)\n",
    "    cv2.circle(pic, (center,130), R, 255, thick)\n",
    "    cv2.rectangle(pic, (center-R-thick,130), (center+R+thick,130+R+thick), 0, -1)\n",
    "    cv2.line(pic, (center-R,130), (center-R,130+470), 255, thick) \n",
    "    cv2.line(pic, (center+R,130), (center+R,130+470), 255, thick) \n",
    "    \n",
    "    if img.shape[1]/img.shape[0] != 116/63:\n",
    "        print('Image shape is not defult:', img.shape)\n",
    "    pic = np.round(cv2.resize(pic, (img.shape[1],img.shape[0]))/255.)*255\n",
    "    \n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a708b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入一个trajectory图片和一个GT图片 输出precision\n",
    "# 根据一个trajectory和一个GT的不同range计算precision\n",
    "def calc_pres(GT, pred):\n",
    "    GT = np.round(GT/255.).astype(int)\n",
    "    pred = np.round(pred/255.).astype(int)\n",
    "    tot = np.count_nonzero(pred)\n",
    "    TP = np.count_nonzero(GT&pred)\n",
    "\n",
    "    return TP/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d12d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算整个trajectory的AP\n",
    "# 输入12个叠在一起的trajectory图片和某trajectory的位置 输出从range1-5曲线下的面积\n",
    "def get_AP(ordered, pos):\n",
    "    AP = 0\n",
    "    pred = ordered[:,:,pos]\n",
    "    for i in range(5):\n",
    "        GT = eva_area(pred, pos, i+1)\n",
    "        Pres = calc_pres(GT, pred)\n",
    "        AP += Pres*0.2\n",
    "        if i == 4 and Pres < 0.99:\n",
    "            print(str(pos), 'This trajectory requires larger range.')\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c284ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算某个trajectory单个section的AP\n",
    "# 输入12个叠在一起的trajectory图片，某trajectory的位置和哪部分线段（前，中，后） 输出从range1-5曲线下的面积\n",
    "def get_AP_section(ordered, pos, section='arc'):\n",
    "    pred = ordered[:,:,pos]\n",
    "    AP = 0\n",
    "    height, width = pred.shape\n",
    "    center = 130+300*(pos//3)\n",
    "    for i in range(5):\n",
    "        GT = eva_area(pred, pos, i+1)\n",
    "        if section == 'arc':\n",
    "            pred_s = pred[:int(13/63*height), :]\n",
    "            GT_s = GT[:int(13/63*height), :]\n",
    "        elif section == 'before':\n",
    "            pred_s = pred[int(13/63*height):, :center]\n",
    "            GT_s = GT[int(13/63*height):, :center]\n",
    "        elif section == 'after':\n",
    "            pred_s = pred[int(13/63*height):, center:]\n",
    "            GT_s = GT[int(13/63*height):, center:]\n",
    "        else:\n",
    "            print('Please input before, arc or after in section.')\n",
    "#         cv2.imwrite('GTtest.png', GT_s)\n",
    "#         cv2.imwrite('Predtest.png', pred_s)\n",
    "        Pres = calc_pres(GT_s, pred_s)\n",
    "        AP += Pres*0.2\n",
    "        if i == 4 and Pres < 0.99:\n",
    "            print(str(pos), 'This trajectory requires larger range.')\n",
    "    return AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ab745fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化单个trajectory AP\n",
    "def view_AP(ordered, pos, rang=1):\n",
    "    blk = np.zeros([ordered.shape[0],ordered.shape[1]])\n",
    "    pred = ordered[:,:,pos]\n",
    "    GT = eva_area(pred, pos, rang)\n",
    "    pred = pred.reshape([ordered.shape[0],ordered.shape[1],1])\n",
    "    GT = GT.reshape([ordered.shape[0],ordered.shape[1],1])\n",
    "    blk = blk.reshape([ordered.shape[0],ordered.shape[1],1])\n",
    "    \n",
    "    overlay = np.concatenate([blk, pred, GT], axis=-1)\n",
    "    return overlay   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ade7e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory 1 AP: 0.9007514831905077\n",
      "trajectory 1 section before AP: 0.8811562385656788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 1 #change trajectory position here (0-11)\n",
    "sec = 'before' # change trajectory section here (before, arc, after)\n",
    "pic = cv2.imread('croped.bmp', 0)\n",
    "ordered = get_traj(pic)\n",
    "print('trajectory %s AP:' %pos, get_AP(ordered, 1))\n",
    "print('trajectory %s section %s AP:' %(pos, sec), get_AP_section(ordered, pos, section=sec))\n",
    "overlay = view_AP(ordered, pos, rang=1)\n",
    "cv2.imwrite('overlay.png', overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc68904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce5d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a64177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从左到右四个是不同的参数 所以这部分用不到了\n",
    "# 输入整个trajectory图片和该trajectory的位置 输出从range1-5曲线下的面积\n",
    "# def get_meanAP(ordered, trajectory='outer'):\n",
    "#     if trajectory == 'outer':\n",
    "#         poses = np.array([0,3,6,9])\n",
    "#     elif trajectory == 'middle':\n",
    "#         poses = np.array([0,3,6,9])+1\n",
    "#     elif trajectory == 'inner':\n",
    "#         poses = np.array([0,3,6,9])+2\n",
    "#     else:\n",
    "#         print('Please define trajectory inner, middle or outer.')\n",
    "#     APs = []\n",
    "#     for pos in poses:\n",
    "#         APs.append(get_AP(ordered[:,:,pos], pos))\n",
    "#     return sum(APs)/len(APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804ce7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 旧的版本 现在应该没用了\n",
    "# 根据evaluate的曲线位置和evaluate的range生成取样区域\n",
    "# def eva_area(img, num=1, loc=1, thick=1):\n",
    "#     center = 130+300*(num-1)\n",
    "#     pic = np.zeros([630, 1160])\n",
    "#     if loc == 1:\n",
    "#         R = 25\n",
    "#     elif loc == 2:\n",
    "#         R = 50\n",
    "#     elif loc == 3:\n",
    "#         R = 100\n",
    "#     else:\n",
    "#         print('Please choose location 1, 2 or 3.')\n",
    "        \n",
    "#     cv2.circle(pic, (center,130), R, 255, thick)\n",
    "#     cv2.rectangle(pic, (center-R-thick,130), (center+R+thick,130+R+thick), 0, -1)\n",
    "#     cv2.line(pic, (center-R,130), (center-R,130+470), 255, thick) \n",
    "#     cv2.line(pic, (center+R,130), (center+R,130+470), 255, thick) \n",
    "    \n",
    "#     if img.shape[1]/img.shape[0] != 116/63:\n",
    "#         print('Image shape is not defult:', img.shape)\n",
    "#     pic = np.round(cv2.resize(pic, (img.shape[1],img.shape[0]))/255.)*255\n",
    "    \n",
    "#     return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6a8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来生成中心线的function\n",
    "# 源代码来源 http://opencvpython.blogspot.com/2012/05/skeletonization-using-opencv-python.html\n",
    "# def Skeletonization(img):\n",
    "#     size = np.size(img)\n",
    "#     skel = np.zeros(img.shape,np.uint8)\n",
    "#     element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "#     done = False\n",
    "\n",
    "#     while( not done):\n",
    "#         eroded = cv2.erode(img,element)\n",
    "#         temp = cv2.dilate(eroded,element)\n",
    "#         temp = cv2.subtract(img,temp)\n",
    "#         skel = cv2.bitwise_or(skel,temp)\n",
    "#         img = eroded.copy()\n",
    "\n",
    "#         zeros = size - cv2.countNonZero(img)\n",
    "#         if zeros==size:\n",
    "#             done = True\n",
    "\n",
    "#     return skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10ec2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好像没用了 只取最大面积的12个部分的话\n",
    "# 移除只有一个pixel的噪音\n",
    "# def remove_1_noise(pic):\n",
    "#     contours, hierarchy = cv2.findContours(pic, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     threshold_blobs_area = 0\n",
    "\n",
    "#     for i in range(1, len(contours)):\n",
    "#         index_level = int(hierarchy[0][i][1])\n",
    "#         if index_level <= i:\n",
    "#             cnt = contours[i]\n",
    "#             area = cv2.contourArea(cnt)\n",
    "#             if area <= threshold_blobs_area:\n",
    "#                 cv2.drawContours(pic, [cnt], -1, 0, -1, 1)\n",
    "#     return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b39db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5ad108ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 1160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic = cv2.imread('o1.bmp',0)\n",
    "print(pic.shape)\n",
    "skl = Skeletonization(pic)\n",
    "# skl = remove_1_noise(skl)\n",
    "cv2.imwrite('o1_clin.bmp', skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b23ab506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(ordered.shape[2]):\n",
    "#     traj = ordered[:,:,i]\n",
    "#     print(traj.shape)\n",
    "#     cline = Skeletonization(traj)\n",
    "#     cv2.imwrite('traj_'+str(i) + '.png', traj)\n",
    "#     cv2.imwrite('cline_'+str(i) + '.png', cline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9cff33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入：原始图片 输出：fiber threshold和中心线\n",
    "def extract_cline_fiber(pic):\n",
    "    # 提取fiber部分\n",
    "    ret,thresh1 = cv2.threshold(pic, 210, 255, cv2.THRESH_BINARY_INV)\n",
    "    blur = cv2.GaussianBlur(thresh1, (5,5), 0)#blur的size可以修改\n",
    "    _, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "#     cv2.imwrite(\"Guassian Otsu's Thresholding.bmp\", th3) \n",
    "    \n",
    "    # 提取centre line部分\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    ret,thresh1 = cv2.threshold(pic, 210, 255, cv2.THRESH_BINARY_INV)\n",
    "    closing = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)\n",
    "    skel = Skeletonization(closing)\n",
    "    skel = remove_1_noise(skel)\n",
    "    \n",
    "    return th3, skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99979532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一键提取center line和fiber的图\n",
    "pic = cv2.imread('220704.bmp',0)\n",
    "th3, skel = extract_cline_fiber(pic)\n",
    "cv2.imwrite('220704fibre.bmp', th3)\n",
    "cv2.imwrite('220704cline.bmp', skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1183ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_areas(contours):\n",
    "    # returns the areas of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f28ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对提取的截取好的（一定和GT重合的）fiber图片进行contour分每个trajectory\n",
    "# def get_trajectory(croped):\n",
    "#     edged = cv2.Canny(np.uint8(croped), 50, 200)\n",
    "#     contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "#     sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#     areas = get_contour_areas(sorted_contours)\n",
    "#     blk_image = np.zeros(croped.shape)\n",
    "#     if len(areas) > 12:\n",
    "#         idx = 12-len(areas)\n",
    "#         if np.any(np.array(areas[idx:]) > 100):\n",
    "#             print('Disconnetion may exist, please check!')\n",
    "#         else:\n",
    "#             n = 0\n",
    "#             for c in sorted_contours:\n",
    "# #                 print(c)\n",
    "#                 cv2.drawContours(blk_image, c, -1, 170, cv2.FILLED)\n",
    "# #                 cv2.drawContours(blk_image,[c],0,(0,255,0),-1)\n",
    "# #                 cv2.drawContours(blk_image, c, 0, 170, cv2.FILLED)\n",
    "# #                 cv2.waitKey(0)\n",
    "#                 cv2.imwrite('contour_' + str(n) + '.png', blk_image)\n",
    "#                 n+=1\n",
    "#     elif len(areas) < 12:\n",
    "#         print('Only %d trajectory detected, please check!' %len(areas))\n",
    "#     print (get_contour_areas(sorted_contours))\n",
    "#     print (\"Number of contours found = \", len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da8e5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试画出来area的新的对提取的截取好的（一定和GT重合的）fiber图片进行contour分每个trajectory\n",
    "def get_trajectory(croped):\n",
    "#     print(np.unique(croped))\n",
    "    edged = cv2.Canny(np.uint8(croped), 50, 200)\n",
    "    ret,thresh1 = cv2.threshold(np.uint8(croped), 210, 255, cv2.THRESH_BINARY_INV)\n",
    "    cv2.imwrite('thistimethresh1.png', thresh1)\n",
    "#     contours, hierarchy = cv2.findContours(thresh1.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    areas = get_contour_areas(sorted_contours)\n",
    "    blk_image = np.zeros(croped.shape)\n",
    "    if len(areas) > 12:\n",
    "        idx = 12-len(areas)\n",
    "        if np.any(np.array(areas[idx:]) > 100):\n",
    "            print('Disconnetion may exist, please check!')\n",
    "        else:\n",
    "            n = 0\n",
    "            for c in sorted_contours:\n",
    "#                 print(c)\n",
    "                cv2.drawContours(blk_image, c, -1, 170, cv2.FILLED)\n",
    "#                 cv2.drawContours(blk_image,[c],0,(0,255,0),-1)\n",
    "#                 cv2.drawContours(blk_image, c, 0, 170, cv2.FILLED)\n",
    "#                 cv2.waitKey(0)\n",
    "                cv2.imwrite('contour_' + str(n) + '.png', blk_image)\n",
    "                n+=1\n",
    "    elif len(areas) < 12:\n",
    "        print('Only %d trajectory detected, please check!' %len(areas))\n",
    "    print (get_contour_areas(sorted_contours))\n",
    "    print (\"Number of contours found = \", len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2c09574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8682.5, 8337.5, 8050.0, 7719.0, 7100.0, 6788.5, 6785.0, 6679.5, 6666.5, 6543.5, 6455.5, 5211.5, 13.0, 10.0, 4.0]\n",
      "Number of contours found =  15\n"
     ]
    }
   ],
   "source": [
    "get_trajectory(croped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ee076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据生成的标准图片eva_area和输入图片计算该选中的area下的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f753e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cf0ac11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里是随便截取一下打印提取的图片 看能不能用来跟上面的eva area重合一下\n",
    "# height, w = th3.shape\n",
    "l,u = 100, 450\n",
    "h = 1000\n",
    "w = int(h/63*116)\n",
    "croped = th3[u:u+h, l:l+w]\n",
    "croped = np.round((cv2.resize(croped, (1160, 630)))/255.).astype(int)*255\n",
    "# print(croped)\n",
    "o1 = eva_area(croped,num=1, loc=3, thick=10).astype(int)\n",
    "np.unique(o1)\n",
    "cv2.imwrite('o1.bmp', o1)\n",
    "cv2.imwrite('croped.bmp', croped)\n",
    "added_image = cv2.addWeighted(croped,0.4,o1,0.3,0)\n",
    "cv2.imwrite('overlay.bmp', added_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9eb111da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 255])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(croped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95496d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe6ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed157693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5698613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434c0b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "15.5\n",
      "1.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "3.0\n",
      "8.5\n",
      "14.5\n",
      "0.0\n",
      "8.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0\n",
      "5.0\n",
      "0.0\n",
      "10.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "33.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "46.0\n",
      "0.0\n",
      "11.5\n",
      "11.0\n",
      "0.0\n",
      "24.0\n",
      "35.5\n",
      "0.0\n",
      "16.0\n",
      "40.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.5\n",
      "3.5\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "32.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "23.0\n",
      "14.5\n",
      "0.0\n",
      "80.0\n",
      "0.0\n",
      "0.0\n",
      "6.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "45.0\n",
      "110.0\n",
      "0.0\n",
      "0.0\n",
      "48.5\n",
      "33.0\n",
      "25.0\n",
      "22.5\n",
      "107.0\n",
      "35.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "30.0\n",
      "74.0\n",
      "0.0\n",
      "40.0\n",
      "8.5\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "61.0\n",
      "0.0\n",
      "95.5\n",
      "39.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "41.0\n",
      "0.0\n",
      "74.5\n",
      "0.0\n",
      "16.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "58.0\n",
      "0.0\n",
      "2.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.5\n",
      "0.0\n",
      "69.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "71.0\n",
      "55.5\n",
      "0.0\n",
      "3.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "48.0\n",
      "0.0\n",
      "0.0\n",
      "84.0\n",
      "97.0\n",
      "0.0\n",
      "33.0\n",
      "0.0\n",
      "2.5\n",
      "82.0\n",
      "107.0\n",
      "0.0\n",
      "0.0\n",
      "14.5\n",
      "10.0\n",
      "0.0\n",
      "68.0\n",
      "47.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "157.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.0\n",
      "33.0\n",
      "32.5\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "24.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "205.5\n",
      "81.0\n",
      "111.5\n",
      "0.0\n",
      "74.0\n",
      "83.5\n",
      "0.0\n",
      "290.0\n",
      "0.0\n",
      "206.0\n",
      "191.5\n",
      "0.0\n",
      "86.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "263.0\n",
      "25.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "97.0\n",
      "0.0\n",
      "1.0\n",
      "171.0\n",
      "17.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "31.0\n",
      "0.0\n",
      "37.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "21.0\n",
      "66.0\n",
      "0.0\n",
      "3.5\n",
      "1.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "317.5\n",
      "37.0\n",
      "0.0\n",
      "54.5\n",
      "0.0\n",
      "0.0\n",
      "50.5\n",
      "1.0\n",
      "157.0\n",
      "0.0\n",
      "18.0\n",
      "12.0\n",
      "8.0\n",
      "13.0\n",
      "0.0\n",
      "0.0\n",
      "152.0\n",
      "0.0\n",
      "71.5\n",
      "16.5\n",
      "0.0\n",
      "10.0\n",
      "0.0\n",
      "107.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "24.0\n",
      "0.0\n",
      "0.0\n",
      "11.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "2.0\n",
      "6.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "11.0\n",
      "0.0\n",
      "0.0\n",
      "6.5\n",
      "124.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.0\n",
      "82.0\n",
      "2.5\n",
      "9.5\n",
      "3.0\n",
      "12.0\n",
      "5.5\n",
      "0.0\n",
      "0.0\n",
      "17.5\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.5\n",
      "12.0\n",
      "12.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "13.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "5.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.0\n",
      "2.0\n",
      "0.0\n",
      "22.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0\n",
      "25.5\n",
      "8.0\n",
      "25.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.5\n",
      "0.0\n",
      "21.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0\n",
      "0.0\n",
      "6.0\n",
      "15.5\n",
      "0.0\n",
      "37.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "24.5\n",
      "29.5\n",
      "0.0\n",
      "42.0\n",
      "31.5\n",
      "0.0\n",
      "0.0\n",
      "12.0\n",
      "0.0\n",
      "0.0\n",
      "28.0\n",
      "14.0\n",
      "20.0\n",
      "13.5\n",
      "10.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.5\n",
      "0.0\n",
      "2.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.0\n",
      "8.5\n",
      "0.0\n",
      "8.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.5\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.0\n",
      "5.5\n",
      "0.0\n",
      "0.0\n",
      "5.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "10.5\n",
      "3.5\n",
      "0.0\n",
      "3.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "18.0\n",
      "5.0\n",
      "0.0\n",
      "0.0\n",
      "1.5\n",
      "6.5\n",
      "0.0\n",
      "0.0\n",
      "13.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.5\n",
      "0.0\n",
      "0.0\n",
      "21.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "13.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.0\n",
      "10.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "20.0\n",
      "11.5\n",
      "0.0\n",
      "4.5\n",
      "0.0\n",
      "0.0\n",
      "21.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "28.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "7.5\n",
      "66.5\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('d3d10597-e629-4f08-853b-75472ae0de06.bmp',0)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "ret,thresh1 = cv2.threshold(image, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "# Closing - for removing noise\n",
    "# blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "# _, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "closing = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite('Closing.bmp', closing)\n",
    "\n",
    "skel = Skeletonization(closing)\n",
    "cv2.imwrite('Closingskel.bmp', skel)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(skel, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "threshold_blobs_area = 0\n",
    "\n",
    "for i in range(1, len(contours)):\n",
    "    index_level = int(hierarchy[0][i][1])\n",
    "    if index_level <= i:\n",
    "        cnt = contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area <= threshold_blobs_area:\n",
    "            cv2.drawContours(skel, [cnt], -1, 0, -1, 1)\n",
    "cv2.imwrite('removednoiseClosingskel.bmp', skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d404fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('d3d10597-e629-4f08-853b-75472ae0de06.bmp',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "cv2.imwrite(\"ADAPTIVE_THRESH_GAUSSIAN Thresholding.bmp\", th3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "259336bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Threshold Binary70.bmp',0)\n",
    "# It's good practice to blur images as it removes noise\n",
    "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "# Using adaptiveThreshold\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                               cv2.THRESH_BINARY, 3, 5) \n",
    "cv2.imwrite(\"Adaptive Mean Thresholding.bmp\", thresh) \n",
    "# cv2.waitKey(0) \n",
    "\n",
    "_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"Otsu's Thresholding.bmp\", th2) \n",
    "# cv2.waitKey(0) \n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"Guassian Otsu's Thresholding.bmp\", th3) \n",
    "\n",
    "# th3 = cv.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,11,2)\n",
    "# cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419cf21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('Threshold Binary70.bmp',0)\n",
    "\n",
    "size = np.size(img)\n",
    "skel = np.zeros(img.shape,np.uint8)\n",
    "\n",
    "ret,img = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "# cv2.imwrite('test.bmp', img)\n",
    "# img = cv2.Canny(img, 300, 120)\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "done = False\n",
    "\n",
    "while( not done):\n",
    "    eroded = cv2.erode(img,element)\n",
    "    temp = cv2.dilate(eroded,element)\n",
    "    temp = cv2.subtract(img,temp)\n",
    "    skel = cv2.bitwise_or(skel,temp)\n",
    "    img = eroded.copy()\n",
    "\n",
    "    zeros = size - cv2.countNonZero(img)\n",
    "    if zeros==size:\n",
    "        done = True\n",
    "\n",
    "cv2.imwrite('skel.bmp', skel)\n",
    "# cv2.imshow(\"skel\",skel)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a7bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('out1.bmp',0)\n",
    "size = np.size(img)\n",
    "skel = np.zeros(img.shape,np.uint8)\n",
    "\n",
    "ret,img = cv2.threshold(img,127,255,0)\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "done = False\n",
    "\n",
    "while( not done):\n",
    "    eroded = cv2.erode(img,element)\n",
    "    temp = cv2.dilate(eroded,element)\n",
    "    temp = cv2.subtract(img,temp)\n",
    "    skel = cv2.bitwise_or(skel,temp)\n",
    "    img = eroded.copy()\n",
    "\n",
    "    zeros = size - cv2.countNonZero(img)\n",
    "    if zeros==size:\n",
    "        done = True\n",
    "\n",
    "cv2.imshow(\"skel\",skel)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d54cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
